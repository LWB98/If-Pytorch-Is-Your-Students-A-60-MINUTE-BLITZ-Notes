源文档：[DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)

环境：Win 10 + JupyterLab 3.3.2 +Conda Environment(dl-env.yaml)

## 5.实战：训练一个分类器

通常，处理图像、文本、音频或视频数据时，就用一些python包将数据加载到 numpy 数组中，然后再把这个数组转换成一个`torch.*Tensor`。

| 数据类型 | 推荐包             |
| -------- | ------------------ |
| 图像     | **Pillow，Pillow** |
| 音频     | **scipy，librosa** |

针对图像数据，Pytorch还有一个`torchvison`的包，它自带了一些常见的数据集(ImageNet、CIFAR10、MNIST)，这样我们做训练时就直接调用加载器`torchvision.datasets`或者转换器`torchvision.datasets`而不用再去找数据下载了。

本次实验我们使用`CIFAR10`数据集构建一个简单的分类器
CIFAR-10 中的图像大小为 3x32x32，即 32x32 像素大小的 3 通道彩色图像。其中包括了‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’十种类别的图片。
![](https://pytorch.org/tutorials/_images/cifar10.png)

本次实验我们具体的步骤如下：

1. 使用`torchvision`加载和规范化`CIFAR10`训练和测试数据集

2. 定义卷积神经网络

3. 定义损失函数

4. 在训练数据上训练网络

5. 在测试数据上测试网络

### 1. 使用`torchvision`加载和规范化`CIFAR10`训练和测试数据集


```python
import torch
import torchvision
import torchvision.transforms as transforms
```

torchvision 数据集的输出是范围 [0, 1] 的 PILImage 图像。我们将它们转换为标准化范围 [-1, 1] 的张量。


```python
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 4

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```

    Files already downloaded and verified
    Files already downloaded and verified



```python
#来check一下我们下载好的数据是不是真的
import matplotlib.pyplot as plt
import numpy as np

# functions to show an image


def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))
```


​    
![png](%E3%80%90%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E3%80%91%E4%BB%A5%E5%AD%A6%E7%94%9F%E7%B1%BB%E6%AF%94Pytorch-60%E5%88%86%E9%92%9F%E9%97%AA%E5%87%BBPytorch%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0_files/%E3%80%90%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E3%80%91%E4%BB%A5%E5%AD%A6%E7%94%9F%E7%B1%BB%E6%AF%94Pytorch-60%E5%88%86%E9%92%9F%E9%97%AA%E5%87%BBPytorch%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0_65_0.png)
​    


    horse plane plane bird 


### 2. 定义卷积神经网络

从之前的神经网络部分复制神经网络并修改它以获取 3 通道图像（而不是定义的 1 通道图像）。


```python
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()
print(net)
```

    Net(
      (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
      (fc1): Linear(in_features=400, out_features=120, bias=True)
      (fc2): Linear(in_features=120, out_features=84, bias=True)
      (fc3): Linear(in_features=84, out_features=10, bias=True)
    )


### 3. 定义损失函数

让我们使用具有动量的分类交叉熵作为损失函数和SGD。(SGD是什么？)


```python
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```

### 4. 在训练数据上训练网络

到了事情开始变得有趣的时候了。我们只需要遍历我们的数据迭代器，并将输入提供给网络并进行优化。


```python
for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
            running_loss = 0.0

print('Finished Training')
```

    [1,  2000] loss: 2.187
    [1,  4000] loss: 1.835
    [1,  6000] loss: 1.661
    [1,  8000] loss: 1.580
    [1, 10000] loss: 1.528
    [1, 12000] loss: 1.477
    [2,  2000] loss: 1.405
    [2,  4000] loss: 1.374
    [2,  6000] loss: 1.349
    [2,  8000] loss: 1.337
    [2, 10000] loss: 1.301
    [2, 12000] loss: 1.293
    Finished Training


接下来我们将模型数据保存到`.pth`文件中，这样我们就能像前文离线下载resnet18模型那样导入我们自己建立的模型了


```python
PATH = './model/cifar_net.pth'
torch.save(net.state_dict(), PATH)
```

### 5. 在测试数据上测试网络

#### 5.1 测试集可视化


```python
dataiter = iter(testloader)
images, labels = dataiter.next()

# print images
imshow(torchvision.utils.make_grid(images))
print('Truth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))
```


​    
![png](%E3%80%90%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E3%80%91%E4%BB%A5%E5%AD%A6%E7%94%9F%E7%B1%BB%E6%AF%94Pytorch-60%E5%88%86%E9%92%9F%E9%97%AA%E5%87%BBPytorch%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0_files/%E3%80%90%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E3%80%91%E4%BB%A5%E5%AD%A6%E7%94%9F%E7%B1%BB%E6%AF%94Pytorch-60%E5%88%86%E9%92%9F%E9%97%AA%E5%87%BBPytorch%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0_79_0.png)
​    


    Truth:  cat   ship  ship  plane


>此时我们已经在训练集上对网络进行了2次训练，此时我们需要在测试集上测试网络的学习情况

我们将通过神经网络输出的类标签与测试集中真实的类标签进行对比，声明一个数列，相同则记为1，不同则即为0，最后统计这个数列中1的占比，即为该神经网络的准确率

#### 5.2 加载模型

我们之前已经将模型保存为`cifar_net.pth`文件了，这里我们通过加载`cifar_net.pth`文件的形式来再生成一次模型（可以不这样做，此处仅作演示）


```python
net = Net()
net.load_state_dict(torch.load(PATH))
```




    <All keys matched successfully>



#### 5.3 抽样查看表现

现在让我们看看我们的网络认为上面的抽取的四张图像分别是什么：

输出有十列，每一列对应每一类的相似指数a(0<a<1)，相似指数越大，网络就认为这个图片更属于其对应的类别，所以，我们输出每行中拥有**最高**相似指数的标签


```python
outputs = net(images)

_, predicted = torch.max(outputs, 1)
#Truth
print('    Truth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))
#predicted
print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'
                              for j in range(4)))
```

        Truth:  cat   ship  ship  plane
    Predicted:  cat   car   plane plane


#### 5.4 查看在整个数据集上的表现


```python
correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in testloader:
        images, labels = data
        # calculate outputs by running images through the network
        outputs = net(images)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')
```

    Accuracy of the network on the 10000 test images: 54 %


看起来这比随机选择一个类(10%)的效果要多了！\滑稽

#### 5.5 查看网络预测每个类别的水平


```python
# prepare to count predictions for each class
correct_pred = {classname: 0 for classname in classes}
total_pred = {classname: 0 for classname in classes}

# again no gradients needed
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predictions = torch.max(outputs, 1)
        # collect the correct predictions for each class
        for label, prediction in zip(labels, predictions):
            if label == prediction:
                correct_pred[classes[label]] += 1
            total_pred[classes[label]] += 1


# print accuracy for each class
for classname, correct_count in correct_pred.items():
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')
```

    Accuracy for class: plane is 62.1 %
    Accuracy for class: car   is 67.7 %
    Accuracy for class: bird  is 36.2 %
    Accuracy for class: cat   is 39.9 %
    Accuracy for class: deer  is 51.0 %
    Accuracy for class: dog   is 58.5 %
    Accuracy for class: frog  is 54.7 %
    Accuracy for class: horse is 53.8 %
    Accuracy for class: ship  is 60.9 %
    Accuracy for class: truck is 64.4 %


文彬